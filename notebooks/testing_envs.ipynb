{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11928400",
   "metadata": {},
   "source": [
    "# Testing envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mique/Desktop/Code/rl-module/app\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "if not os.getcwd().endswith(\"app\"):\n",
    "    os.chdir(\"../app\")\n",
    "    print(os.getcwd())\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7ed54",
   "metadata": {},
   "source": [
    "# 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8f18214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________\n",
      "[[2 0 0 0]\n",
      " [4 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "________________________________________________________________\n",
      "[[2 0 0 0]\n",
      " [4 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "________________________________________________________________\n",
      "[[2 0 0 0]\n",
      " [4 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "________________________________________________________________\n",
      "[[0 0 0 2]\n",
      " [0 0 0 4]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "________________________________________________________________\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [2 0 0 0]\n",
      " [4 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from src.custom_envs import Env2048\n",
    "from maikol_utils.print_utils import print_separator\n",
    "\n",
    "env = Env2048(new_boxes_per_step=1)\n",
    "state, info = env.reset(42)\n",
    "for s in state:\n",
    "    print_separator()\n",
    "    print(s.T) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bf43cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward = np.float64(0.00244140625)\n",
      "terminated = False\n",
      "truncated = False\n",
      "________________________________________________________________\n",
      "[[0 0 0 2]\n",
      " [0 0 2 4]\n",
      " [0 2 0 0]\n",
      " [0 0 0 2]]\n",
      "________________________________________________________________\n",
      "[[2 0 0 0]\n",
      " [2 4 0 0]\n",
      " [2 0 0 0]\n",
      " [2 0 0 0]]\n",
      "________________________________________________________________\n",
      "[[0 2 2 2]\n",
      " [0 0 0 4]\n",
      " [0 0 0 2]\n",
      " [0 0 0 0]]\n",
      "________________________________________________________________\n",
      "[[0 0 0 2]\n",
      " [0 0 2 4]\n",
      " [0 0 0 2]\n",
      " [0 0 0 2]]\n",
      "________________________________________________________________\n",
      "[[0 0 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 0 4]\n",
      " [0 2 2 2]]\n"
     ]
    }
   ],
   "source": [
    "state, reward, terminated, truncated, info = env.step(2)\n",
    "print(f\"{reward = }\")\n",
    "print(f\"{terminated = }\")\n",
    "print(f\"{truncated = }\")\n",
    "for s in state:\n",
    "    print_separator()\n",
    "    print(s.T) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29087616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0,  0,  2],\n",
       "       [ 8,  0,  0,  0],\n",
       "       [ 2,  2,  2,  0],\n",
       "       [ 4,  4,  8,  4]], dtype=int16)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, reward, terminated, truncated, info = env.step(3)\n",
    "state.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71793b",
   "metadata": {},
   "source": [
    "### Playing with trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a085b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functions import evaluate_agent\n",
    "from src.utils import load_agent, set_seed\n",
    "\n",
    "from src.config import Configuration\n",
    "\n",
    "from maikol_utils.file_utils import clear_directories, make_dirs\n",
    "from maikol_utils.print_utils import print_separator\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "from maikol_utils.print_utils import print_separator\n",
    "from maikol_utils.time_tracker import print_time\n",
    "\n",
    "from src.models import get_envs, handle_states\n",
    "\n",
    "\n",
    "CONFIG = Configuration(\n",
    "    env_id=\"Env2048\",\n",
    "    exp_name=\"Env2048\",\n",
    "    record_video=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "535443ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________\n",
      "                                                         CONFIGURATION                                                          \n",
      "\n",
      " - Loading agent at ../models/Env2048/Env2048-v0.pt\n",
      " - Creating vars...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 2.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 2.]],\n",
       "\n",
       "        [[0., 4., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 4., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 2., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 4., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 4., 0.],\n",
       "         [4., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_separator(\"CONFIGURATION\", sep_type=\"LONG\")\n",
    "make_dirs(CONFIG.videos_path)\n",
    "\n",
    "envs = get_envs(CONFIG, evaluating=True)\n",
    "agent = load_agent(CONFIG)\n",
    "\n",
    "print(f\" - Creating vars...\")\n",
    "episode_rewards = []\n",
    "states = handle_states(CONFIG, envs.reset()[0])\n",
    "dones = torch.zeros(CONFIG.n_envs, dtype=bool)\n",
    "start_time = time()\n",
    "\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f001c0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================\n",
      "                                                           EVALUATING                                                           \n",
      "================================================================================================================================\n",
      "\n",
      " - Evaluating for 20000.\n",
      "actions = tensor([1, 1, 1, 1], device='cuda:0')\n",
      "dones = array([False, False, False, False])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 8,  2,  8,  0],\n",
       "        [ 2, 32,  2,  4],\n",
       "        [16, 32,  0,  0],\n",
       "        [ 4,  0,  0,  0]],\n",
       "\n",
       "       [[ 4,  2,  0,  0],\n",
       "        [ 4,  8,  0,  0],\n",
       "        [ 0,  0,  2,  0],\n",
       "        [ 0,  0,  0,  0]],\n",
       "\n",
       "       [[ 2, 16,  2, 16],\n",
       "        [16,  4, 16, 32],\n",
       "        [16,  8,  2,  0],\n",
       "        [ 4,  4,  0,  0]],\n",
       "\n",
       "       [[ 2,  8,  4,  2],\n",
       "        [ 8,  4, 32,  4],\n",
       "        [ 2,  8,  2,  4],\n",
       "        [ 4,  2,  0,  0]]], dtype=int16)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================================================\n",
    "#                       EVALUATING LOOP\n",
    "# ================================================================\n",
    "print_separator(\"EVALUATING\", sep_type=\"SUPER\")\n",
    "print(f\" - Evaluating for {CONFIG.n_eval_steps}.\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    actions, _, _, _ = agent.get_action_value(states)\n",
    "\n",
    "print(f\"{actions = }\")\n",
    "\n",
    "next_states, rewards, terms, truncs, infos = envs.step(actions.cpu().numpy())\n",
    "states = handle_states(CONFIG, next_states)\n",
    "dones = terms | truncs\n",
    "\n",
    "episode_rewards.append(np.array(rewards))\n",
    "print(f\"{dones = }\")\n",
    "\n",
    "if all(dones): # stop early if all envs finished an episode\n",
    "    print(\"DONE!\")\n",
    "\n",
    "next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80229b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "#                            DONE\n",
    "# ================================================================\n",
    "print_separator(\"RESUME\", sep_type=\"LONG\")\n",
    "envs.close()\n",
    "# If no rewards collected -> return NaNs (safe)\n",
    "if len(episode_rewards) == 0:\n",
    "    mean_reward, std_reward = float(\"nan\"), float(\"nan\")\n",
    "else:\n",
    "    # episode_rewards: list of (T, n_envs) per-step reward arrays\n",
    "    rewards_arr = np.stack(episode_rewards, axis=0)      \n",
    "    per_env_returns = rewards_arr.sum(axis=0)         \n",
    "    mean_reward = float(np.mean(per_env_returns))\n",
    "    std_reward  = float(np.std(per_env_returns))\n",
    "\n",
    "print(f\" - Mean rewards: {mean_reward:.4f}+-{std_reward:.4f}\")\n",
    "print_time(time() - start_time, prefix=\" - \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
